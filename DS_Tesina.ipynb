{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Imports section<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Spaces' Tesina <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn import neighbors, model_selection, metrics, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Read .csv file <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"dataR2.csv\"\n",
    "file = open(filename, \"r\")\n",
    "\n",
    "data = np.loadtxt(file, delimiter=\",\", dtype=None, encoding=None, usecols=(0,1,2,3,4,5,6,7,8,9), skiprows=1)\n",
    "\n",
    "# records with the classification as \"1\" are Healthy Controls, \"2\" means Patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Preprocessing</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's divide data into source and target (respectively X and Y)\n",
    "X = data[:, :-1]\n",
    "Y = data[:, len(data[0])-1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, random_state=np.random.randint(0,100), test_size=0.3)\n",
    "\n",
    "# array of possible K to apply KNN neighbors\n",
    "ks = [3,5,7,9]\n",
    "\n",
    "\n",
    "# normalize data because algorithms work better with normalized data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> I try to apply PCA on the dataset, since there are 10 features (which are a lot) and then re-apply KNN <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca.fit(X)\n",
    "# Xp = pca.transform(X)\n",
    "# print(Xp)\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = model_selection.train_test_split(Xp, Y, random_state=np.random.randint(0,100), test_size=0.3)\n",
    "\n",
    "# # array of possible K to apply KNN neighbors\n",
    "# ks = [3,5,7,9]\n",
    "\n",
    "\n",
    "# # normalize data because algorithms work better with normalized data\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Apply K-NN</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the test set with K = 3 is 0.686\n",
      "Accuracy score on the test set with K = 5 is 0.743\n",
      "Accuracy score on the test set with K = 7 is 0.771\n",
      "Accuracy score on the test set with K = 9 is 0.771\n"
     ]
    }
   ],
   "source": [
    "for k in ks:\n",
    "    n_neighbors = k\n",
    "    \n",
    "    # Create an instance of neighbors classifier (clf) and fit the data\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "    \n",
    "    # train the classifier on the training set\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Accuracy score on the test set with K =\",n_neighbors,\"is %.3f\" %(clf.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Apply KNN this time with a validation set </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best K, based on the validation set results, is 3 and the accuracy on the test set is 0.829\n"
     ]
    }
   ],
   "source": [
    "# Let's create the validation set\n",
    "X_train_t, X_valid, Y_train_t, Y_valid = model_selection.train_test_split(X_train, Y_train, random_state=np.random.randint(0,100), test_size=0.30)\n",
    "\n",
    "# array of possible K to apply KNN neighbors\n",
    "ks = [3,5,7,9]\n",
    "\n",
    "# normalize data because algorithms work better with normalized data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "\n",
    "# array to write accuracy values for each K \n",
    "acc_arr = []\n",
    "\n",
    "for k in ks:\n",
    "    n_neighbors = k\n",
    "    \n",
    "    # Create an instance of neighbors classifier (clf) and fit the data\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "    \n",
    "    # train the classifier on the training set\n",
    "    clf.fit(X_train_t, Y_train_t)\n",
    "    \n",
    "    acc_arr.append(clf.score(X_valid, Y_valid))\n",
    "    \n",
    "# I choose the best K based on the results on the validation set and apply KNN with that\n",
    "k_best_index = acc_arr.index(max(acc_arr))\n",
    "k_best = ks[k_best_index]\n",
    "\n",
    "clf2 = neighbors.KNeighborsClassifier(k_best)\n",
    "clf2.fit(X_train_t, Y_train_t)\n",
    "\n",
    "print(\"The best K, based on the validation set results, is\",k_best,\"and the accuracy on the test set is %.3f\"%(clf2.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> I'll try Logistic Regression on the dataset <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7714285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaelthur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression() # instance of the model\n",
    "\n",
    "logReg.fit(X_train, Y_train)\n",
    "\n",
    "# res = logReg.predict(X_test)\n",
    "\n",
    "print(logReg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><u> Naive Bayes classifier </u></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "print(gnb.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
