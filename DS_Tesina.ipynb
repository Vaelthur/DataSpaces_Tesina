{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Spaces' Tesina <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Imports section<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import neighbors, model_selection, metrics, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Read .csv file <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = \"dataR2.csv\"\n",
    "file = open(filename, \"r\")\n",
    "\n",
    "# data_complete = np.loadtxt(file, delimiter=\",\", dtype=None, encoding=None, usecols=(0,1,2,3,4,5,6,7,8,9), skiprows=1)\n",
    "\n",
    "# according to the relevant papers indicated in the website where I took this dataset from has been has been\n",
    "# observed that if instead of taking into account all of the features we only take 4 of them (Age, BMI, Glucose\n",
    "# & Resistine) we can achieve a grater accuracy (only if we are using the SVM or at least Random Forest algos\n",
    "# whereas with KNN or Logistic regression results aren't that nice).\n",
    "\n",
    "data = np.loadtxt(file, delimiter=\",\", dtype=None, encoding=None, usecols=(0,1,2,7,9), skiprows=1)\n",
    "\n",
    "# records with the classification as \"1\" are Healthy Controls, \"2\" means Patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><p>Preprocessing<p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's divide data into source and target (respectively X and Y)\n",
    "X = data[:, :-1]\n",
    "Y = data[:, len(data[0])-1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, random_state=np.random.randint(0,100), test_size=0.27)\n",
    "\n",
    "# array of possible K to apply KNN neighbors\n",
    "ks = [3,5,7,9]\n",
    "\n",
    "\n",
    "# normalize data because algorithms work better with normalized data\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><u>K-NN</u></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the test set with K = 3 is 0.688\n",
      "Accuracy score on the test set with K = 5 is 0.750\n",
      "Accuracy score on the test set with K = 7 is 0.719\n",
      "Accuracy score on the test set with K = 9 is 0.719\n"
     ]
    }
   ],
   "source": [
    "for k in ks:\n",
    "    n_neighbors = k\n",
    "    \n",
    "    # Create an instance of neighbors classifier (clf) and fit the data\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "    \n",
    "    # train the classifier on the training set\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Accuracy score on the test set with K =\",n_neighbors,\"is %.3f\" %(clf.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><u>Logistic Regression</u><p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.71      0.71      0.71        17\n",
      "         2.0       0.67      0.67      0.67        15\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.69      0.69      0.69        32\n",
      "weighted avg       0.69      0.69      0.69        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(solver=\"lbfgs\") # instance of the model\n",
    "\n",
    "logReg.fit(X_train, Y_train)\n",
    "\n",
    "# res = logReg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", logReg.score(X_test, Y_test))\n",
    "print(classification_report(Y_test, logReg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><u> Random forest</u> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.78125\n"
     ]
    }
   ],
   "source": [
    "rndFor = RandomForestClassifier(n_estimators = 200, criterion=\"entropy\")\n",
    "\n",
    "rndFor.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = rndFor.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><u> SVM</u> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8125\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='auto', kernel='rbf')\n",
    "svc.fit(X_train, Y_train)\n",
    "print(\"Accuracy: \", svc.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> So this is the accuracy with the default parameters, but with SVm approach is necessary to perform some parameters tuning in order to achieve a better result. To do so I relied on the GridSearch <p>\n",
    "<p><u> SVM with GridSearch </u></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.88      0.82      0.85        17\n",
      "         2.0       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.84      0.85      0.84        32\n",
      "weighted avg       0.85      0.84      0.84        32\n",
      " \n",
      "\n",
      "Confusion Matrix:\n",
      " [[14  3]\n",
      " [ 2 13]]\n",
      "Area Under the ROC curve:  0.8450980392156862\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'C': [0.1, 0.2, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [0.1, 0.2, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 0.25, 1], 'kernel': ['rbf']}]\n",
    "svcGS = GridSearchCV(svc, parameters, n_jobs=-1, cv=5, refit=True)\n",
    "svcGS.fit(X_train, Y_train)\n",
    "# print(\"Accuracy: \", svcGS.score(X_test, Y_test))\n",
    "print(classification_report(Y_test, svcGS.predict(X_test)),\"\\n\")\n",
    "cm = metrics.confusion_matrix(Y_test, svcGS.predict(X_test))\n",
    "\n",
    "print (\"Confusion Matrix:\\n\",cm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, svcGS.predict(X_test), pos_label=2)\n",
    "print(\"Area Under the ROC curve: \",metrics.auc(fpr, tpr))                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The result above shows us a fuller report. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
